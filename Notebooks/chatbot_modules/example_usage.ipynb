{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Пример использования модульного чат-бота\n",
                "\n",
                "В этом ноутбуке показано, как использовать модульный чат-бот с Retrieval-Augmented Generation (RAG)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Добавляем директорию с модулями в путь поиска\n",
                "sys.path.append('..')\n",
                "\n",
                "# Загружаем переменные окружения из .env\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Импорт необходимых модулей"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.chat_models import ChatOpenAI\n",
                "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
                "from langchain_chroma import Chroma\n",
                "from langchain_community.retrievers import BM25Retriever\n",
                "from langchain.retrievers import EnsembleRetriever\n",
                "from langchain.schema import Document\n",
                "\n",
                "from chatbot_modules import RAGChatBot"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Загрузка векторного хранилища и создание ретривера"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/h2/r9wh0x750xq4v5z33ylwrzw40000gn/T/ipykernel_62093/1143437512.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
                        "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
                        "/Users/sergey/Desktop/Voise_RAG/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "# Загрузка модели эмбеддингов\n",
                "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
                "\n",
                "# Загрузка векторного хранилища\n",
                "vector_store = Chroma(\n",
                "    collection_name=\"knowledge_markdown\",\n",
                "    embedding_function=embeddings,\n",
                "    persist_directory=\"../chroma_langchain_db/knowledge\"\n",
                ")\n",
                "\n",
                "# Создание ретривера по векторной близости\n",
                "similarity_retriever = vector_store.as_retriever(\n",
                "    search_type=\"similarity\",\n",
                "    search_kwargs={\"k\": 5}\n",
                ")\n",
                "\n",
                "# Извлечение всех документов для BM25 ретривера\n",
                "raw_collection = vector_store._collection.get()\n",
                "docs = []\n",
                "\n",
                "# Проверка наличия документов\n",
                "if \"documents\" in raw_collection and raw_collection[\"documents\"]:\n",
                "    for content, meta in zip(raw_collection[\"documents\"], raw_collection[\"metadatas\"]):\n",
                "        docs.append(Document(page_content=content, metadata=meta))\n",
                "    \n",
                "    # Создание BM25 ретривера только если есть документы\n",
                "    if docs:\n",
                "        keyword_retriever = BM25Retriever.from_documents(docs)\n",
                "        keyword_retriever.k = 5\n",
                "        \n",
                "        # Создание ансамбля ретриверов\n",
                "        ensemble_retriever = EnsembleRetriever(\n",
                "            retrievers=[similarity_retriever, keyword_retriever],\n",
                "            weights=[0.5, 0.5]\n",
                "        )\n",
                "    else:\n",
                "        print(\"Предупреждение: Нет документов для BM25Retriever, используется только векторный поиск\")\n",
                "        ensemble_retriever = similarity_retriever\n",
                "else:\n",
                "    print(\"Предупреждение: Нет документов в векторном хранилище, используется только векторный поиск\")\n",
                "    ensemble_retriever = similarity_retriever"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Создание языковой модели"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/h2/r9wh0x750xq4v5z33ylwrzw40000gn/T/ipykernel_62093/2590432426.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
                        "  llm = ChatOpenAI(\n"
                    ]
                }
            ],
            "source": [
                "# Проверка наличия API ключа\n",
                "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
                "if not api_key:\n",
                "    raise ValueError(\"API ключ не найден. Укажите его в .env файле или переменной окружения.\")\n",
                "\n",
                "# Создание модели\n",
                "llm = ChatOpenAI(\n",
                "    openai_api_key=api_key,\n",
                "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
                "    model_name=\"deepseek/deepseek-r1-distill-llama-8b\",  # Можно заменить на другую модель\n",
                "    temperature=0.5,\n",
                "    max_tokens=2048,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Создание чат-бота"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/sergey/Desktop/Voise_RAG/Notebooks/chatbot_modules/../chatbot_modules/chat.py:55: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
                        "  self.memory = ConversationBufferMemory(\n",
                        "/Users/sergey/Desktop/Voise_RAG/Notebooks/chatbot_modules/../chatbot_modules/chat.py:140: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
                        "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
                        "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
                        "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
                        "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
                        "\n",
                        "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
                        "  self.qa_chain = load_qa_chain(\n",
                        "/Users/sergey/Desktop/Voise_RAG/Notebooks/chatbot_modules/../chatbot_modules/chat.py:148: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
                        "  self.web_search_chain = LLMChain(\n",
                        "/Users/sergey/Desktop/Voise_RAG/Notebooks/chatbot_modules/../chatbot_modules/chat.py:160: LangChainDeprecationWarning: The class `ConversationalRetrievalChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~create_history_aware_retriever together with create_retrieval_chain (see example in docstring)` instead.\n",
                        "  self.chain = ConversationalRetrievalChain(\n"
                    ]
                },
                {
                    "ename": "ValidationError",
                    "evalue": "1 validation error for ConversationalRetrievalChain\nquestion_generator\n  Field required [type=missing, input_value={'retriever': EnsembleRet...source_documents': True}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Создание чат-бота\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m chatbot = \u001b[43mRAGChatBot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensemble_retriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./response_cache.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Путь к файлу для сохранения кэша\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_web_search\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Использовать поиск в интернете\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_web_search_attempts\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Максимальное количество попыток поиска в интернете\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_relevant_sources\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Максимальное количество релевантных источников\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Voise_RAG/Notebooks/chatbot_modules/../chatbot_modules/chat.py:79\u001b[39m, in \u001b[36mRAGChatBot.__init__\u001b[39m\u001b[34m(self, llm, retriever, cache_file, use_web_search, max_web_search_attempts, max_relevant_sources)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28mself\u001b[39m._create_prompts()\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Создание цепочки для обработки запросов\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Voise_RAG/Notebooks/chatbot_modules/../chatbot_modules/chat.py:160\u001b[39m, in \u001b[36mRAGChatBot._create_chain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.combine_chain = LLMChain(\n\u001b[32m    155\u001b[39m     llm=\u001b[38;5;28mself\u001b[39m.llm,\n\u001b[32m    156\u001b[39m     prompt=\u001b[38;5;28mself\u001b[39m.combine_prompt\n\u001b[32m    157\u001b[39m )\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# Создание основной цепочки для обработки запросов\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28mself\u001b[39m.chain = \u001b[43mConversationalRetrievalChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcombine_docs_chain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqa_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    165\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Voise_RAG/venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:214\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    213\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Voise_RAG/venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Voise_RAG/venv/lib/python3.12/site-packages/pydantic/main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
                        "\u001b[31mValidationError\u001b[39m: 1 validation error for ConversationalRetrievalChain\nquestion_generator\n  Field required [type=missing, input_value={'retriever': EnsembleRet...source_documents': True}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
                    ]
                }
            ],
            "source": [
                "# Создание чат-бота\n",
                "chatbot = RAGChatBot(\n",
                "    llm=llm,\n",
                "    retriever=ensemble_retriever,\n",
                "    cache_file=\"./response_cache.json\",  # Путь к файлу для сохранения кэша\n",
                "    use_web_search=True,  # Использовать поиск в интернете\n",
                "    max_web_search_attempts=3,  # Максимальное количество попыток поиска в интернете\n",
                "    max_relevant_sources=3  # Максимальное количество релевантных источников\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Тестирование чат-бота"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Тестовый вопрос\n",
                "question = \"Как правильно мыть двигатель автомобиля?\"\n",
                "\n",
                "# Получение ответа\n",
                "response = chatbot.answer(question)\n",
                "\n",
                "# Вывод ответа\n",
                "print(f\"Вопрос: {question}\\n\")\n",
                "print(f\"Ответ: {response['answer']}\\n\")\n",
                "\n",
                "# Вывод источников\n",
                "if response[\"sources\"]:\n",
                "    print(\"Источники:\")\n",
                "    for source in response[\"sources\"]:\n",
                "        print(f\"- {source}\")\n",
                "\n",
                "# Вывод информации о времени выполнения и использовании веб-поиска\n",
                "print(f\"\\nВремя выполнения: {response['time_taken']:.2f} сек.\")\n",
                "if response[\"used_web_search\"]:\n",
                "    print(\"Использован поиск в интернете\")\n",
                "if response[\"from_cache\"]:\n",
                "    print(\"Ответ получен из кэша\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Интерактивный чат"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Запуск интерактивного чата\n",
                "# Для выхода введите 'х'\n",
                "chatbot.run_interactive_chat()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
